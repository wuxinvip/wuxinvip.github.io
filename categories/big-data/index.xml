<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Big Data on 无心技术簿</title>
    <link>https://blog.wuxinvip.com/categories/big-data/</link>
    <description>Recent content in Big Data on 无心技术簿</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Jun 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://blog.wuxinvip.com/categories/big-data/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>hadoop 简介</title>
      <link>https://blog.wuxinvip.com/blog/big-data/hadoop/hadoop-1/</link>
      <pubDate>Wed, 20 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wuxinvip.com/blog/big-data/hadoop/hadoop-1/</guid>
      <description>hadoop发展史
Hadoop Apache Lucene创始人Doug Cutting 创建 基于 Nutch开发 本身也是lucence一部分
2004年 Doug Cutting 和Mike Cafarella 实现 HDFS和MapReduce初版
2005年 Nutch移植到新框架 Hadoop再20个节点稳定运行
2006年1月 Doug Cutting 加入雅虎 2006年2月 Apache Hadoop项目正式启动、支持MapReduce和HDFS独立发展 2006年4月 再188节点上（每节点10GB数据）运行排序测试集群需要47.9小时 2006年5月 雅虎建立一个300个节点的Hadoop研究集群 2006年5月 在500个节点运行排序测试集需要42个小时（硬件配置比四月份更优秀） 2006年11月 研究集群增加到600个节点 2006年12月 排序测试集在20个节点上运行1.8个小时、100个节点运行3.3个小时、500个节点运行5.2小时、900个节点需要7.8个小时。
2007年1月 研究集群增加到900个节点 2007年4月 研究集群增加到两个集群1000个节点
2008年4月 在900个节点上运行1TB排序测试集仅需要209秒 2008年10月 研究集群每天装载10TB数据
2009年3月 17个集群共24000个节点 2009年4月 在每分钟排序中胜出、59秒排序500GB（在1400个节点）、173分钟排序100TB数据（在3400节点）
 hadoop简介
大数据处理、应对数据处理出现的新的技术、 底层也就是大名鼎鼎的HDFS文件系统 对数据并发处理有极强的性能
  hadoop-wiki
 hadoop应用场景
随着数据量的增大、数据量已经到了PB级别、数据的存储也需要更加强大的技术来支持、
 hadoop组件
namenode节点负责存储目录 datanode节点负责存储数据
Map函数 接受一个键值对（key-value pair），产生一组中间键值对。 MapReduce框架会将map函数产生的中间键值对里键相同的值传递给一个reduce函数。 Reduce函数 接受一个键，以及相关的一组值，将这组值进行合并产生一组规模更小的值（通常只有一个或零个值）。</description>
    </item>
    
    <item>
      <title>spark 简介</title>
      <link>https://blog.wuxinvip.com/blog/big-data/spark/spark-1/</link>
      <pubDate>Wed, 20 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://blog.wuxinvip.com/blog/big-data/spark/spark-1/</guid>
      <description>spark发展史
Apache Spark Spark Logo 开发者 Apache软件基金会, 加州大学柏克莱分校AMPLab, Databricks 稳定版本 2.1.0 （2016年12月28日 ） 开发状态 活跃 编程语言 Scala, Java, Python 操作系统 Linux, Mac OS, Microsoft Windows 类型 数据分析, 机器学习算法 许可协议 Apache许可协议 2.0 网站 spark.apache.org 源代码库 github.com/apache/spark Apache Spark是一个开源集群运算框架，最初是由加州大学柏克莱分校AMPLab所开发。 相对于Hadoop的MapReduce会在运行完工作后将中介数据存放到磁盘中，Spark使用了存储器内运算技术，能在数据尚未写入硬盘时即在存储器内分析运算。 Spark在存储器内运行程序的运算速度能做到比Hadoop MapReduce的运算速度快上100倍，即便是运行程序于硬盘时，Spark也能快上10倍速度。 [1]Spark允许用户将数据加载至集群存储器，并多次对其进行查询，非常适合用于机器学习算法。
 spark简介
 spark应用场景
使用Spark需要搭配集群管理员和分布式存储系统。 Spark支持独立模式（本地Spark集群）、Hadoop YARN或Apache Mesos的集群管理。 [3] 在分布式存储方面，Spark可以和HDFS[4]、 Cassandra[5] 、OpenStack Swift和Amazon S3等接口搭载。 Spark也支持伪分布式（pseudo-distributed）本地模式，不过通常只用于开发或测试时以本机文件系统取代分布式存储系统。 在这样的情况下，Spark仅在一台机器上使用每个CPU核心运行程序。
 spark组件
Spark核心是整个项目的基础，提供了分布式任务调度，调度和基本的I／O功能。而其基础的程序抽象则称为弹性分布式数据集（RDDs），是一个可以并行操作、有容错机制的数据集合。 RDDs可以通过引用外部存储系统的数据集创建（例如：共享文件系统、HDFS、HBase或其他 Hadoop 数据格式的数据源）。 或者是通过在现有RDDs的转换而创建（比如：map、filter、reduce、join等等）。
RDD抽象化是经由一个以Scala, Java, Python的语言集成API所呈现，简化了编程复杂性，应用程序操纵RDDs的方法类似于操纵本地端的数据集合。
 spark集群</description>
    </item>
    
  </channel>
</rss>