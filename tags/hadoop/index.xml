<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hadoop on 无心技术簿</title>
    <link>https://www.wuxinvip.com/tags/hadoop/</link>
    <description>Recent content in Hadoop on 无心技术簿</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Jun 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://www.wuxinvip.com/tags/hadoop/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>hadoop 简介</title>
      <link>https://www.wuxinvip.com/blog/big-data/hadoop/hadoop-1/</link>
      <pubDate>Wed, 20 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.wuxinvip.com/blog/big-data/hadoop/hadoop-1/</guid>
      <description>hadoop发展史
Hadoop Apache Lucene创始人Doug Cutting 创建 基于 Nutch开发 本身也是lucence一部分
2004年 Doug Cutting 和Mike Cafarella 实现 HDFS和MapReduce初版
2005年 Nutch移植到新框架 Hadoop再20个节点稳定运行
2006年1月 Doug Cutting 加入雅虎 2006年2月 Apache Hadoop项目正式启动、支持MapReduce和HDFS独立发展 2006年4月 再188节点上（每节点10GB数据）运行排序测试集群需要47.9小时 2006年5月 雅虎建立一个300个节点的Hadoop研究集群 2006年5月 在500个节点运行排序测试集需要42个小时（硬件配置比四月份更优秀） 2006年11月 研究集群增加到600个节点 2006年12月 排序测试集在20个节点上运行1.8个小时、100个节点运行3.3个小时、500个节点运行5.2小时、900个节点需要7.8个小时。
2007年1月 研究集群增加到900个节点 2007年4月 研究集群增加到两个集群1000个节点
2008年4月 在900个节点上运行1TB排序测试集仅需要209秒 2008年10月 研究集群每天装载10TB数据
2009年3月 17个集群共24000个节点 2009年4月 在每分钟排序中胜出、59秒排序500GB（在1400个节点）、173分钟排序100TB数据（在3400节点）
 hadoop简介
大数据处理、应对数据处理出现的新的技术、 底层也就是大名鼎鼎的HDFS文件系统 对数据并发处理有极强的性能
  hadoop-wiki
 hadoop应用场景
随着数据量的增大、数据量已经到了PB级别、数据的存储也需要更加强大的技术来支持、
 hadoop组件
namenode节点负责存储目录 datanode节点负责存储数据
Map函数 接受一个键值对（key-value pair），产生一组中间键值对。 MapReduce框架会将map函数产生的中间键值对里键相同的值传递给一个reduce函数。 Reduce函数 接受一个键，以及相关的一组值，将这组值进行合并产生一组规模更小的值（通常只有一个或零个值）。</description>
    </item>
    
  </channel>
</rss>