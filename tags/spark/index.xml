<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Spark on 无心技术簿</title>
    <link>http://wuxinvip.github.io/tags/spark/</link>
    <description>Recent content in Spark on 无心技术簿</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Jun 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://wuxinvip.github.io/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>spark 简介</title>
      <link>http://wuxinvip.github.io/blog/big-data/spark/spark-1/</link>
      <pubDate>Wed, 20 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>http://wuxinvip.github.io/blog/big-data/spark/spark-1/</guid>
      <description>spark发展史
Apache Spark Spark Logo 开发者 Apache软件基金会, 加州大学柏克莱分校AMPLab, Databricks 稳定版本 2.1.0 （2016年12月28日 ） 开发状态 活跃 编程语言 Scala, Java, Python 操作系统 Linux, Mac OS, Microsoft Windows 类型 数据分析, 机器学习算法 许可协议 Apache许可协议 2.0 网站 spark.apache.org 源代码库 github.com/apache/spark Apache Spark是一个开源集群运算框架，最初是由加州大学柏克莱分校AMPLab所开发。 相对于Hadoop的MapReduce会在运行完工作后将中介数据存放到磁盘中，Spark使用了存储器内运算技术，能在数据尚未写入硬盘时即在存储器内分析运算。 Spark在存储器内运行程序的运算速度能做到比Hadoop MapReduce的运算速度快上100倍，即便是运行程序于硬盘时，Spark也能快上10倍速度。 [1]Spark允许用户将数据加载至集群存储器，并多次对其进行查询，非常适合用于机器学习算法。
 spark简介
 spark应用场景
使用Spark需要搭配集群管理员和分布式存储系统。 Spark支持独立模式（本地Spark集群）、Hadoop YARN或Apache Mesos的集群管理。 [3] 在分布式存储方面，Spark可以和HDFS[4]、 Cassandra[5] 、OpenStack Swift和Amazon S3等接口搭载。 Spark也支持伪分布式（pseudo-distributed）本地模式，不过通常只用于开发或测试时以本机文件系统取代分布式存储系统。 在这样的情况下，Spark仅在一台机器上使用每个CPU核心运行程序。
 spark组件
Spark核心是整个项目的基础，提供了分布式任务调度，调度和基本的I／O功能。而其基础的程序抽象则称为弹性分布式数据集（RDDs），是一个可以并行操作、有容错机制的数据集合。 RDDs可以通过引用外部存储系统的数据集创建（例如：共享文件系统、HDFS、HBase或其他 Hadoop 数据格式的数据源）。 或者是通过在现有RDDs的转换而创建（比如：map、filter、reduce、join等等）。
RDD抽象化是经由一个以Scala, Java, Python的语言集成API所呈现，简化了编程复杂性，应用程序操纵RDDs的方法类似于操纵本地端的数据集合。
 spark集群</description>
    </item>
    
  </channel>
</rss>